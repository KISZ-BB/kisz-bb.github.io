---
title: Weekly Paper Readings
showthedate: false
image: "/img/logo_4.png"
date: 2024-06-01

weight: 4
---

# AI Maker Community - Weekly Paper Readings

* [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980) `Deep Learning`

* [A Guide to Convolution Arithmetic for Deep Learning](https://arxiv.org/abs/1603.07285) `Deep Learning` `Computer Vision`

* [Algorithms for Hyper-parameter Optimization](https://papers.nips.cc/paper_files/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html) `Machine Learning Theory`

* [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) `Computer Vision`, `Deep Learning`

* [Attention is All You Need](https://arxiv.org/abs/1706.03762) `NLP`, `Deep Learning`

* [Auto-encoding Variational Bayes](https://arxiv.org/abs/1312.6114) `Deep Learning`

* [Axiomatic Attribution for Deep Networks](https://arxiv.org/abs/1703.01365) `Deep Learning`, `Computer Vision`

* [Bag of Tricks for Image Classification with Convolutional Neural Networks](https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf) `Computer Vision`, `Deep Learning`

* [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167) `Deep Learning`

* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) `NLP`, `Deep Learning`

* [Binarized Neural Networks](https://arxiv.org/abs/1602.02830) `Deep Learning`

* [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629) `Deep Learning`, `Machine Learning Theory`

* [Confident Learning: Estimating Uncertainty in Dataset Labels](https://arxiv.org/abs/1911.00068) `Machine Learning Theory`

* [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186) `Deep Learning`

* [Deep Residual Networks for Image Recognition](https://arxiv.org/abs/1512.03385) `Computer Vision`, `Deep Learning`

* [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290) `Reinforcement Learning`, `NLP`

* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning](https://arxiv.org/abs/1506.02142) `Deep Learning`, `Machine Learning Theory`

* [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://jmlr.org/papers/v15/srivastava14a.html) `Deep Learning`

* [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) `Computer Vision`, `Deep Learning`

* [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135) `Deep Learning`

* [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) `Deep Learning`

* [Genie: Generative Interactive Environments](https://arxiv.org/abs/2402.15391) `Reinforcement Learning`

* [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391) `Computer Vision`, `Deep Learning`

* [Graph Neural Networks: A Review of Methods and Applications](https://arxiv.org/abs/1812.08434v6) `Deep Learning`

* [Hidden Technical Debt in Machine Learning Systems](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf) `MLOps` `Machine Learning Theory`

* [High Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) `Computer Vision`, `Deep Learning`

* [ImageNet Classification with Deep Convolutional Networks](https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) `Computer Vision`, `Deep Learning`

* [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) `NLP`, `Deep Learning`

* [Learning Deep Features for Discriminative Localization](https://arxiv.org/abs/1512.04150) `Computer Vision`, `Deep Learning`

* [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) `Computer Vision`, `NLP`, `Deep Learning`

* [LightGBM: A Highly Efficient Gradient Boosting Decision Tree](https://papers.nips.cc/paper_files/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html) `Machine Learning Theory`

* [LLama2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288) `NLP`, `Deep Learning`

* [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) `NLP`, `Deep Learning`

* [Long Short-Term Memory](https://www.bioinf.jku.at/publications/older/2604.pdf) `Deep Learning`

* [Long-form Factuality in Large Language Models](https://arxiv.org/abs/2403.18802) `NLP`, `Deep Learning`

* [MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution](https://arxiv.org/abs/2403.17927) `NLP`, `Deep Learning`

* [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752) `Deep Learning`

* [Mask R-CNN](https://arxiv.org/abs/1703.06870) `Computer Vision`, `Deep Learning`

* [No-Free Lunch Theorems for Optimization](https://www.cs.ubc.ca/~hutter/earg/papers07/00585893.pdf) `Machine Learning Theory`

* [Panoptic Segmentation](https://arxiv.org/abs/1801.00868) `Computer Vision`, `Deep Learning`

* [Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602) `Reinforcement Learning`

* [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314) `Deep Learning`, `NLP`

* [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) `NLP`, `Reinforcement Learning`

* [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401) `NLP`, `Deep Learning`

* [RWKV: Reinventing RNNs for the Transformer Era](https://arxiv.org/abs/2305.13048) `Deep Learning`

* [Segment Anything](https://arxiv.org/abs/2304.02643) `Computer Vision`, `Deep Learning`

* [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf) `Machine Learning Theory`

* [The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective](https://link.springer.com/article/10.3758/s13423-016-1221-4) `Machine Learning Theory`

* [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/abs/2402.17764) `NLP`, `Deep Learning`

* [The M6 forecasting competition: Bridging the gap between forecasting and investment decisions](https://arxiv.org/abs/2310.13357) `Machine Learning Theory`

* [The Matrix Calculus You Need for Deep Learning](https://arxiv.org/abs/1802.01528) `Deep Learning`

* [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) `Deep Learning`

* [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597) `Computer Vision`, `Deep Learning`

* [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901) `Computer Vision`, `Deep Learning`

* [When Do Neural Nets Outperform Boosted Trees on Tabular Data?](https://arxiv.org/abs/2305.02997) `Deep Learning`, `Machine Learning Theory`
